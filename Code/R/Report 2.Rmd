---
title: "Report-II 2021 Operational Statistics SAR"
author: "Chen yicong,Guo Zhengxi,Liu Zhenyuan,Tian Shunli"
date: "2021/10/20"
output: 
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(reshape2)
require(ggplot2)
require(ggthemes)
theme_set(theme_minimal())
require(GGally)
require(ggExtra)
require(tinytex)
```

## Implement the densities of the K and G0 distributions for intensity data

Firstly, We will import the bright image data from the "ImagematrXI" library for analysis.

```{r LoadUrbanHVData}
# Use your paths
source("../../Code/R/imagematrix.R")
load("../../Data/R/bright.Rdata")
# Inspect what they are in the Environment window
```

Then the report will give the basic information of the data, including its type, dimension, range, etc.

```{r Quantitative_EDA_Urban}
typeof(bright)
dim(bright)
range(bright)

vector.bright <- data.frame(bright=as.vector(bright))
summary(vector.bright)
```

Then we use boxplot and histograms to analyze the data, and outliers are represented in blue

```{r Graphical_EDA_Urban_Boxplot, fig.cap='Boxplots with notches', fig.subcap=c('Linear scale', 'Semilogarithmic scale'), out.width = "50%", fig.align = "center"}
ggplot(vector.bright, aes(x=bright)) +
  geom_boxplot(notch = TRUE)+
  geom_boxplot(outlier.colour="blue", outlier.shape=7,outlier.size=1)+
  ggtitle("bright")

ggplot(vector.bright, aes(x=bright)) +
  geom_boxplot(notch = TRUE) +
  geom_boxplot(outlier.colour="blue", outlier.shape=7,outlier.size=1)+
  scale_x_log10()+
  ggtitle("bright in semilog scale")
```

First, we get the box plot of the bright image data, which is the "bright" plot on the left. It can be observed that the "bright" graphic frame is so flat. Therefore, we perform logarithmic transformation on the data to get the box plot titled "Semi-Logarithmic Brightness" in the figure below.

As we have observed in the "semi-logarithmic brightness" graph, the average value of the data is around 10^5, with little fluctuation.

Histograms of the data complement the information are shown by the boxplots. We also use the Freedman-Diaconis rule for building the histograms, which consists of using bins of equal size: $\frac32 \text{IQR}(z) / n^{1/3}$.

```{r Graphical_EDA_Urban_Histogram, fig.cap='Histograms', fig.subcap=c('Linear scale', 'Semilogarithmic scale'), out.width = "50%", fig.align = "center"}
ggplot(vector.bright, aes(x=bright)) +
  geom_histogram(aes(y=..density..),
                 bins=nclass.FD(unlist(vector.bright)),
                 col="yellow", fill="white")+
  ggtitle("bright")

ggplot(vector.bright, aes(x=bright)) +
  geom_histogram(aes(y=..density..),
                 bins=nclass.FD(unlist(vector.bright)),
                 col="yellow", fill="white") +
  scale_x_log10()+
  ggtitle("bright in semilog scale")
```
Now let's merge the second boxplot from the second histogram as follows:

```{r Graphical_EDA_BoxplotAndHistogram}
ggplot(vector.bright, aes(x=bright)) +
  geom_histogram(aes(y=..density..),
                 bins=nclass.FD(unlist(vector.bright)),
                 col="yellow", fill="white") +
  geom_boxplot(aes(y=0.8), width=.1,col="orange", notch=TRUE) +
  ylab("Density and Boxplot") +
  xlab("Intensity in semilogarithmic scale") +
  scale_x_log10()
# Try reducing the number of bins
```
Through the above analysis, we can draw the following three conclusions:

* Data is positive
* Data has a large dynamic range
* The data is somewhat symmetrical

Then, we can focus on the "natural" field of data: images.
The data range required by the imagematrix library is between $[0,1]$. We execute a function to complete this mapping.

```{r}
plot(imagematrix(normalize(bright)))
```

However, in the above image, we can observe some subtle things. The reason may be that there are some very large values that make most observations "flatten out" to very deep grays. Instead, we want to "use" all possible values equally. In other words, we want a uniform histogram.

Consider the cumulative distribution function $F_Z$ of the continuous random variable $Zcolon \Omega\to\mathbb R$, then the random variable $W=F_Z(Z)$ has a uniform distribution.

It can be proved that the cumulative distribution function of $W$ is $F_W(W)=/Pr(W/leq W)=/Pr(F_Z(Z)/leq W)$.
Since $Z$ is continuous, its cumulative distribution function $F^{-1}_Z$ has a reciprocal.
Then we can write it as
USD F_W (w) = PR (F_Z (Z) / leq w) = PR (F ^ (1) _Z (F_Z (Z)) \ leq F_Z ^ (1) (w)) = PR (Z \ leq F ^ {1} _Z (w)) $.
This is exactly the cumulative distribution function of $Z$ at $F^{-1}_Z(w)$, so we can prove that $F_W(w) = F_Z(F^{-1}_Z(w))=w$ , It represents a uniform random variable on $(0,1)$.

Therefore, we need to apply the cumulative distribution function of the random variable that generates the data to the data itself to get a uniformly distributed sample. Unfortunately, we do not have such a function, but we can estimate it.

One of the easiest ways to estimate the cumulative distribution function from the data $z=(z_1,\dots,z_n)$ is to use the empirical cumulative distribution function, or simply "empirical function".
It is only a finite approximation defined by the cumulative distribution 
formula
\begin{equation}
\ wide-hat {F}(t) = frac1n # # # j # text{ such that} z_j/leq t/} ,
\End of the Dusk {formula}
where $#$ denotes the number of elements in the set.

The original data and its empirical function are shown as following:

```{r OriginalDataEmpiricalFunction}
ggplot(vector.bright, aes(x=bright)) +
  geom_histogram(aes(y=..density..),
                 bins=nclass.FD(unlist(vector.bright))/50,
                 col="blue", fill="white") +
  stat_ecdf(col="yellow") +
  ylab("Density and Empirical function") +
  xlab("Intensity in semilogarithmic scale") +
  scale_x_log10()
```

These data can be implemented as follows:

```{r HistogramEqualization}
# First, we compute the empirical function
ecdf.bright <- ecdf(unlist(vector.bright))

# Then, we apply this function to the data
eq.bright <- ecdf.bright(unlist(vector.bright))

# Finally, we restore the matrix organization of the data
dim(eq.bright) <- dim(bright)

# And we see the result
plot(imagematrix(eq.bright))
```

Now, we can perform EDA on the balanced data.

```{r EDA_EqualizedData}
summary(as.vector(eq.bright))

vector.eq.bright <- data.frame(eq.bright=as.vector(eq.bright))
                              
ggplot(vector.eq.bright, aes(x=eq.bright)) +
  geom_histogram(aes(y=..density..),
                 bins=nclass.FD(unlist(vector.eq.bright)),
                 col="black", fill="white") +
  geom_boxplot(aes(y=1.2), width=.1, notch=TRUE) +
  ylab("Density and Boxplot") +
  xlab("Equalized data") 

```

As can be seen from the above figure, the pixels of the new image after transformation are evenly distributed.

For the sake of simplicity, we can also directly perform logarithmic transformation on the data, and the result is shown in the figure below.

```{r LogarithmImageTransformation}
plot(imagematrix(normalize(log(bright))))
```

When changing the parameters in the histogram, we can see the following results.
We can use an example of size $n=300$ to perform an example of this effect.

#Gamma Distribution

```{r BinSizeEffect, fig.cap='Histograms', fig.subcap=c('Default bin size', 'Freedmand-Diaconis bin size', "Improved histogram"), out.width = "50%", fig.align = "center"}
x <- data.frame(x=rgamma(300, shape=2, scale=1))

ggplot(x, aes(x=x)) +
  geom_histogram(aes(y=..density..),
                 col="green", fill="white") +
  ylab("Proportions histogram")

ggplot(x, aes(x=x)) +
  geom_histogram(aes(y=..density..),
                 bins=nclass.FD(unlist(x)),
                 col="green", fill="white") +
  ylab("Proportions histogram")

ggplot(x, aes(x=x)) +
  geom_density(col="pink", size=2) +
  geom_histogram(aes(y=..density..),
                 bins=nclass.FD(unlist(x)), 
                 alpha=0.5, fill="#33AADE", color="black") +
  ylab("Histogram and smoothed histogram")

```

By comparing the first picture and the second picture, the result shows that the larger the number of boxes, the more data can be obtained and the more difficult it is to process.


#The definition of K-Distribution

```{r KI_Distributions_definition}
# This block is the K PDF & K-distributions random generator.
dKI <- function(z, p_alpha, p_lambda, p_Looks, log=FALSE) {
  
  if(log==FALSE) {
    
    lLz <- p_lambda * p_Looks* z
    
    return((2*p_lambda*p_Looks/(gamma(p_alpha)*gamma(p_Looks))) *
             (lLz)^((p_alpha+p_Looks)/2-1) *
             besselK(x = 2*sqrt(lLz), nu = p_alpha-p_Looks)
    )
  }
  
}


rKI <- function(n, p_alpha,p_lambda, p_Looks) {
  
  return(
    rgamma(n, 1, p_Looks)*rgamma(n, p_alpha/p_lambda, p_alpha)
  )
  
}
```

#The definition of G0-Distribution

```{r GI0_Distributions_definition}
# This block is the G0 PDF & G0-distributions random generator.
dGI0 <- function(z, p_alpha, p_gamma, p_Looks, log=FALSE) {
  
  if(log==TRUE) {
    return(
      (p_Looks*log(p_Looks) + lgamma(p_Looks-p_alpha) + (p_Looks-1)*log(z) ) - 
        (p_alpha*log(p_gamma) + lgamma(-p_alpha) + lgamma(p_Looks) + 
        (p_Looks-p_alpha)*log(p_gamma + z*p_Looks) ) 
      )   
    }
  else { return( 
    ( p_Looks^p_Looks * gamma(p_Looks-p_alpha) * z^(p_Looks-1) ) / 
    (p_gamma^p_alpha * gamma(-p_alpha) * gamma(p_Looks) * (p_gamma + z*p_Looks)^(p_Looks-p_alpha)) 
  )
  }
}


rGI0 <- function(n, p_alpha, p_gamma, p_Looks) {
  
  return(
    rgamma(n, 1, p_Looks) / rgamma(n, -p_alpha, p_gamma)
  )
  
}
```


#Different parameters for the Gamma-Distribution

```{r Gamma-Distributions}
# Gamma Distributions (PDF & CDF)
ggplot(data=data.frame(x=seq(1e-3, 5, length.out = 1e3)), aes(x=x)) +
  stat_function(fun=dgamma, geom = "line", size=1, col="yellow", args = list(shape=1, scale=1)) +
  stat_function(fun=dgamma, geom = "line", size=1, col="pink", args = list(shape=3, scale=1/3)) +
  stat_function(fun=dgamma, geom = "line", size=1, col="blue", args = list(shape=8, scale=1/8)) +
  theme_classic() +
  theme(text = element_text(size=10)) +
  xlab("x") + ylab("Gamma PDF")

ggplot(data=data.frame(x=seq(1e-3, 5, length.out = 1e3)), aes(x=x)) +
  stat_function(fun=pgamma, geom = "line", size=1, col="yellow", args = list(shape=1, scale=1)) +
  stat_function(fun=pgamma, geom = "line", size=1, col="pink", args = list(shape=3, scale=1/3)) +
  stat_function(fun=pgamma, geom = "line", size=1, col="blue", args = list(shape=8, scale=1/8)) +
  theme_classic() +
  theme(text = element_text(size=10)) +
  xlab("x") + ylab("Gamma CDF")

```

#Different parameters for the K-Distribution

```{r K_Distributions}
# K Distributions (PDF)
ggplot(data=data.frame(x=seq(1e-3, 5, length.out = 1e3)), aes(x=x)) +
  stat_function(fun=dKI, geom = "line", size=1, col="yellow", args = list(p_alpha=1, p_lambda=1, p_Looks=1)) +
  stat_function(fun=dKI, geom = "line", size=1, col="pink", args = list(p_alpha=3, p_lambda=3, p_Looks=2)) +
  stat_function(fun=dKI, geom = "line", size=1, col="blue", args = list(p_alpha=8, p_lambda=8, p_Looks=3)) +
  xlab("x") + 
  ylab("K PDF")+
  scale_x_log10()
```


#Different parameters for the G0-Distribution

```{r G0_Distributions}
# G0 Distributions (PDF)
ggplot(data=data.frame(x=seq(1e-3, 5, length.out = 1e3)), aes(x=x)) +
  stat_function(fun=dGI0, geom = "line", size=1, col="yellow", args = list(p_alpha=-1.5, p_gamma=.5, p_Looks=1)) +
  stat_function(fun=dGI0, geom = "line", size=1, col="pink", args = list(p_alpha=-3, p_gamma=2, p_Looks=2)) +
  stat_function(fun=dGI0, geom = "line", size=1, col="blue", args = list(p_alpha=-8, p_gamma=7, p_Looks=3)) +
  xlab("x") + ylab("G0 PDF")+
  scale_x_log10()
```



#Random number generator for K(p_alpha, p_lambda, p_Looks)

```{r KI_random}
# k-distribution random generator
p_alpha=3
p_lambda=2
p_Looks=1
pk_num=1e5

# K-random
x<-rKI(pk_num, p_alpha, p_lambda, p_Looks) 
x<-data.frame(x) # x~K(p_alpha, p_lambda, p_Looks)

ggplot(x, aes(x=x)) +
  geom_histogram(aes(y=..density..),alpha=0.5, fill="#6495ED",        color="black",bins=nclass.FD(unlist(x))/10) +
  geom_density(col="orange", size=1) +
  geom_boxplot(aes(y=1), width=.1)+
  stat_ecdf(col="red") +
  ylab("Histogram & smoothed histogram")+
  scale_x_log10()


ggplot(data=data.frame(x=seq(1e-5, 1e2, length.out = 1e5)), aes(x=x)) +
  stat_function(fun=dgamma, geom = "line", size=1, col="red", args = list(shape=1, scale=p_Looks)) +
  stat_function(fun=dgamma, geom = "line", size=1, col="orange", args = list(shape=p_alpha/p_lambda, scale=p_alpha)) +
  stat_function(fun=dKI, geom = "line", size=1, col="green", args = list(p_alpha=p_alpha, p_lambda=p_lambda, p_Looks=p_Looks)) +
  xlab("x") + ylab("R-gamma(1,L), B-gamma(a/l,a), G-K(a,l,L)")+
  scale_x_log10()

```
#Random number generator for G0(p_alpha, p_gamma, p_Looks)

```{r GI0_random}
# G0-distribution random generator
p_alpha=-2
p_gamma=.5 
p_Looks=1.5
pG0_num=1e5

# G0-random
x<-rGI0(pG0_num,p_alpha, p_gamma, p_Looks)
x<-data.frame(x) # x~G0(p_alpha, p_gamma, p_Looks)

ggplot(x, aes(x=x)) +
  geom_histogram(aes(y=..density..),alpha=0.5, fill="#6495ED",        color="black",bins=nclass.FD(unlist(x))/500) +
  geom_density(col="orange", size=1) +
  geom_boxplot(aes(y=1), width=.1)+
  stat_ecdf(col="red") +
  ylab("Histogram & smoothed histogram")+
  scale_x_log10()


ggplot(data=data.frame(x=seq(1e-5, 1e2, length.out = 1e5)), aes(x=x)) +
  stat_function(fun=dgamma, geom = "line", size=1, col="red", args = list(shape=1, scale=p_Looks)) +
  stat_function(fun=dgamma, geom = "line", size=1, col="orange", args = list(shape=-p_alpha, scale=p_gamma)) +
  stat_function(fun=dGI0, geom = "line", size=1, col="green", args = list(p_alpha=p_alpha, p_gamma=p_gamma, p_Looks=p_Looks)) +
  xlab("x") + ylab("R-gamma(1,L), B-gamma(-a,g), G-G0(a,g,L)")+
  scale_x_log10()

```



